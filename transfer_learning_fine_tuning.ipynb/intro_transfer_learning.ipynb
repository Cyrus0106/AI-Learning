{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5834767f",
   "metadata": {},
   "source": [
    "### Introduction to Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b21d6",
   "metadata": {},
   "source": [
    "## What is Transfer Learning?\n",
    "\n",
    "Transfer learning is a machine learning technique where a model developed for one task is reused as the starting point for a model on a second, related task. Instead of training a model from scratch, transfer learning leverages pre-trained models—often trained on large datasets—and fine-tunes them on a smaller, task-specific dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- **Reuse of Knowledge:** Transfer learning enables the knowledge gained from solving one problem to be applied to a different but related problem, reducing the need to learn everything from scratch.\n",
    "- **Pre-trained Models:** Models trained on large-scale datasets (such as ImageNet for images or massive text corpora for NLP) serve as the foundation. These models have already learned useful features and representations.\n",
    "- **Fine-tuning:** The pre-trained model is adapted (fine-tuned) to the new task using a smaller, task-specific dataset. This process is faster and requires fewer resources than training from scratch.\n",
    "- **Improved Performance:** Transfer learning often leads to better performance, especially when the new dataset is small or labeled data is scarce.\n",
    "- **Reduced Computational Cost:** Leveraging pre-trained models significantly reduces the computational resources and time required for training.\n",
    "\n",
    "---\n",
    "\n",
    "### How Transfer Learning Differs from Traditional Training\n",
    "\n",
    "| Traditional Training                | Transfer Learning                        |\n",
    "|--------------------------------------|------------------------------------------|\n",
    "| Model is trained from scratch        | Starts with a pre-trained model          |\n",
    "| Requires large amounts of data       | Can work with smaller datasets           |\n",
    "| Longer training times                | Faster convergence and reduced training time |\n",
    "| No prior knowledge is leveraged      | Utilizes knowledge from previous tasks   |\n",
    "| Feature extraction is task-specific  | General features are reused and adapted  |\n",
    "\n",
    "---\n",
    "\n",
    "### Benefits of Transfer Learning\n",
    "\n",
    "- **Reduced Training Time:**  \n",
    "    Pre-trained models already capture foundational features, so fewer epochs are needed to adapt to the new task.\n",
    "- **Improved Performance on Small Datasets:**  \n",
    "    Transfer learning allows effective training even when data is limited, as the model starts with useful representations.\n",
    "- **Leverages Generalization:**  \n",
    "    Pre-trained models generalize better across tasks due to exposure to large-scale and diverse datasets.\n",
    "- **Lower Resource Requirements:**  \n",
    "    Less computational power and time are needed compared to training a model from scratch.\n",
    "- **Faster Experimentation:**  \n",
    "    Researchers and practitioners can iterate more quickly by building on existing models.\n",
    "\n",
    "---\n",
    "\n",
    "### Applications of Transfer Learning\n",
    "\n",
    "#### In Computer Vision\n",
    "\n",
    "Pre-trained models such as **ResNet**, **VGG**, **Inception**, and **EfficientNet** are widely used for:\n",
    "- **Object Detection:** Identifying and localizing objects within images (e.g., YOLO, Faster R-CNN).\n",
    "- **Image Classification:** Assigning labels to images based on their content.\n",
    "- **Image Segmentation:** Partitioning images into meaningful segments (e.g., U-Net for medical imaging).\n",
    "\n",
    "#### In Natural Language Processing (NLP)\n",
    "\n",
    "Models like **BERT**, **GPT**, **T5**, and **RoBERTa** are fine-tuned for:\n",
    "- **Text Classification:** Categorizing text into predefined classes (e.g., spam detection, topic classification).\n",
    "- **Sentiment Analysis:** Determining the sentiment expressed in text (positive, negative, neutral).\n",
    "- **Named Entity Recognition (NER):** Identifying entities such as names, locations, and organizations in text.\n",
    "- **Question Answering:** Building systems that can answer questions based on context or documents.\n",
    "- **Machine Translation:** Translating text from one language to another.\n",
    "\n",
    "---\n",
    "\n",
    "Transfer learning is a powerful paradigm that accelerates the development of machine learning solutions, especially in domains where labeled data is scarce or expensive to obtain. It is a cornerstone of modern AI, enabling rapid progress in fields such as computer vision, NLP, speech recognition, and beyond.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b95156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d90b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: input_layer_1, Trainable: True\n",
      "Layer 1: conv1_pad, Trainable: True\n",
      "Layer 2: conv1_conv, Trainable: True\n",
      "Layer 3: conv1_bn, Trainable: True\n",
      "Layer 4: conv1_relu, Trainable: True\n",
      "Layer 5: pool1_pad, Trainable: True\n",
      "Layer 6: pool1_pool, Trainable: True\n",
      "Layer 7: conv2_block1_1_conv, Trainable: True\n",
      "Layer 8: conv2_block1_1_bn, Trainable: True\n",
      "Layer 9: conv2_block1_1_relu, Trainable: True\n",
      "Layer 10: conv2_block1_2_conv, Trainable: True\n",
      "Layer 11: conv2_block1_2_bn, Trainable: True\n",
      "Layer 12: conv2_block1_2_relu, Trainable: True\n",
      "Layer 13: conv2_block1_0_conv, Trainable: True\n",
      "Layer 14: conv2_block1_3_conv, Trainable: True\n",
      "Layer 15: conv2_block1_0_bn, Trainable: True\n",
      "Layer 16: conv2_block1_3_bn, Trainable: True\n",
      "Layer 17: conv2_block1_add, Trainable: True\n",
      "Layer 18: conv2_block1_out, Trainable: True\n",
      "Layer 19: conv2_block2_1_conv, Trainable: True\n",
      "Layer 20: conv2_block2_1_bn, Trainable: True\n",
      "Layer 21: conv2_block2_1_relu, Trainable: True\n",
      "Layer 22: conv2_block2_2_conv, Trainable: True\n",
      "Layer 23: conv2_block2_2_bn, Trainable: True\n",
      "Layer 24: conv2_block2_2_relu, Trainable: True\n",
      "Layer 25: conv2_block2_3_conv, Trainable: True\n",
      "Layer 26: conv2_block2_3_bn, Trainable: True\n",
      "Layer 27: conv2_block2_add, Trainable: True\n",
      "Layer 28: conv2_block2_out, Trainable: True\n",
      "Layer 29: conv2_block3_1_conv, Trainable: True\n",
      "Layer 30: conv2_block3_1_bn, Trainable: True\n",
      "Layer 31: conv2_block3_1_relu, Trainable: True\n",
      "Layer 32: conv2_block3_2_conv, Trainable: True\n",
      "Layer 33: conv2_block3_2_bn, Trainable: True\n",
      "Layer 34: conv2_block3_2_relu, Trainable: True\n",
      "Layer 35: conv2_block3_3_conv, Trainable: True\n",
      "Layer 36: conv2_block3_3_bn, Trainable: True\n",
      "Layer 37: conv2_block3_add, Trainable: True\n",
      "Layer 38: conv2_block3_out, Trainable: True\n",
      "Layer 39: conv3_block1_1_conv, Trainable: True\n",
      "Layer 40: conv3_block1_1_bn, Trainable: True\n",
      "Layer 41: conv3_block1_1_relu, Trainable: True\n",
      "Layer 42: conv3_block1_2_conv, Trainable: True\n",
      "Layer 43: conv3_block1_2_bn, Trainable: True\n",
      "Layer 44: conv3_block1_2_relu, Trainable: True\n",
      "Layer 45: conv3_block1_0_conv, Trainable: True\n",
      "Layer 46: conv3_block1_3_conv, Trainable: True\n",
      "Layer 47: conv3_block1_0_bn, Trainable: True\n",
      "Layer 48: conv3_block1_3_bn, Trainable: True\n",
      "Layer 49: conv3_block1_add, Trainable: True\n",
      "Layer 50: conv3_block1_out, Trainable: True\n",
      "Layer 51: conv3_block2_1_conv, Trainable: True\n",
      "Layer 52: conv3_block2_1_bn, Trainable: True\n",
      "Layer 53: conv3_block2_1_relu, Trainable: True\n",
      "Layer 54: conv3_block2_2_conv, Trainable: True\n",
      "Layer 55: conv3_block2_2_bn, Trainable: True\n",
      "Layer 56: conv3_block2_2_relu, Trainable: True\n",
      "Layer 57: conv3_block2_3_conv, Trainable: True\n",
      "Layer 58: conv3_block2_3_bn, Trainable: True\n",
      "Layer 59: conv3_block2_add, Trainable: True\n",
      "Layer 60: conv3_block2_out, Trainable: True\n",
      "Layer 61: conv3_block3_1_conv, Trainable: True\n",
      "Layer 62: conv3_block3_1_bn, Trainable: True\n",
      "Layer 63: conv3_block3_1_relu, Trainable: True\n",
      "Layer 64: conv3_block3_2_conv, Trainable: True\n",
      "Layer 65: conv3_block3_2_bn, Trainable: True\n",
      "Layer 66: conv3_block3_2_relu, Trainable: True\n",
      "Layer 67: conv3_block3_3_conv, Trainable: True\n",
      "Layer 68: conv3_block3_3_bn, Trainable: True\n",
      "Layer 69: conv3_block3_add, Trainable: True\n",
      "Layer 70: conv3_block3_out, Trainable: True\n",
      "Layer 71: conv3_block4_1_conv, Trainable: True\n",
      "Layer 72: conv3_block4_1_bn, Trainable: True\n",
      "Layer 73: conv3_block4_1_relu, Trainable: True\n",
      "Layer 74: conv3_block4_2_conv, Trainable: True\n",
      "Layer 75: conv3_block4_2_bn, Trainable: True\n",
      "Layer 76: conv3_block4_2_relu, Trainable: True\n",
      "Layer 77: conv3_block4_3_conv, Trainable: True\n",
      "Layer 78: conv3_block4_3_bn, Trainable: True\n",
      "Layer 79: conv3_block4_add, Trainable: True\n",
      "Layer 80: conv3_block4_out, Trainable: True\n",
      "Layer 81: conv4_block1_1_conv, Trainable: True\n",
      "Layer 82: conv4_block1_1_bn, Trainable: True\n",
      "Layer 83: conv4_block1_1_relu, Trainable: True\n",
      "Layer 84: conv4_block1_2_conv, Trainable: True\n",
      "Layer 85: conv4_block1_2_bn, Trainable: True\n",
      "Layer 86: conv4_block1_2_relu, Trainable: True\n",
      "Layer 87: conv4_block1_0_conv, Trainable: True\n",
      "Layer 88: conv4_block1_3_conv, Trainable: True\n",
      "Layer 89: conv4_block1_0_bn, Trainable: True\n",
      "Layer 90: conv4_block1_3_bn, Trainable: True\n",
      "Layer 91: conv4_block1_add, Trainable: True\n",
      "Layer 92: conv4_block1_out, Trainable: True\n",
      "Layer 93: conv4_block2_1_conv, Trainable: True\n",
      "Layer 94: conv4_block2_1_bn, Trainable: True\n",
      "Layer 95: conv4_block2_1_relu, Trainable: True\n",
      "Layer 96: conv4_block2_2_conv, Trainable: True\n",
      "Layer 97: conv4_block2_2_bn, Trainable: True\n",
      "Layer 98: conv4_block2_2_relu, Trainable: True\n",
      "Layer 99: conv4_block2_3_conv, Trainable: True\n",
      "Layer 100: conv4_block2_3_bn, Trainable: True\n",
      "Layer 101: conv4_block2_add, Trainable: True\n",
      "Layer 102: conv4_block2_out, Trainable: True\n",
      "Layer 103: conv4_block3_1_conv, Trainable: True\n",
      "Layer 104: conv4_block3_1_bn, Trainable: True\n",
      "Layer 105: conv4_block3_1_relu, Trainable: True\n",
      "Layer 106: conv4_block3_2_conv, Trainable: True\n",
      "Layer 107: conv4_block3_2_bn, Trainable: True\n",
      "Layer 108: conv4_block3_2_relu, Trainable: True\n",
      "Layer 109: conv4_block3_3_conv, Trainable: True\n",
      "Layer 110: conv4_block3_3_bn, Trainable: True\n",
      "Layer 111: conv4_block3_add, Trainable: True\n",
      "Layer 112: conv4_block3_out, Trainable: True\n",
      "Layer 113: conv4_block4_1_conv, Trainable: True\n",
      "Layer 114: conv4_block4_1_bn, Trainable: True\n",
      "Layer 115: conv4_block4_1_relu, Trainable: True\n",
      "Layer 116: conv4_block4_2_conv, Trainable: True\n",
      "Layer 117: conv4_block4_2_bn, Trainable: True\n",
      "Layer 118: conv4_block4_2_relu, Trainable: True\n",
      "Layer 119: conv4_block4_3_conv, Trainable: True\n",
      "Layer 120: conv4_block4_3_bn, Trainable: True\n",
      "Layer 121: conv4_block4_add, Trainable: True\n",
      "Layer 122: conv4_block4_out, Trainable: True\n",
      "Layer 123: conv4_block5_1_conv, Trainable: True\n",
      "Layer 124: conv4_block5_1_bn, Trainable: True\n",
      "Layer 125: conv4_block5_1_relu, Trainable: True\n",
      "Layer 126: conv4_block5_2_conv, Trainable: True\n",
      "Layer 127: conv4_block5_2_bn, Trainable: True\n",
      "Layer 128: conv4_block5_2_relu, Trainable: True\n",
      "Layer 129: conv4_block5_3_conv, Trainable: True\n",
      "Layer 130: conv4_block5_3_bn, Trainable: True\n",
      "Layer 131: conv4_block5_add, Trainable: True\n",
      "Layer 132: conv4_block5_out, Trainable: True\n",
      "Layer 133: conv4_block6_1_conv, Trainable: True\n",
      "Layer 134: conv4_block6_1_bn, Trainable: True\n",
      "Layer 135: conv4_block6_1_relu, Trainable: True\n",
      "Layer 136: conv4_block6_2_conv, Trainable: True\n",
      "Layer 137: conv4_block6_2_bn, Trainable: True\n",
      "Layer 138: conv4_block6_2_relu, Trainable: True\n",
      "Layer 139: conv4_block6_3_conv, Trainable: True\n",
      "Layer 140: conv4_block6_3_bn, Trainable: True\n",
      "Layer 141: conv4_block6_add, Trainable: True\n",
      "Layer 142: conv4_block6_out, Trainable: True\n",
      "Layer 143: conv5_block1_1_conv, Trainable: True\n",
      "Layer 144: conv5_block1_1_bn, Trainable: True\n",
      "Layer 145: conv5_block1_1_relu, Trainable: True\n",
      "Layer 146: conv5_block1_2_conv, Trainable: True\n",
      "Layer 147: conv5_block1_2_bn, Trainable: True\n",
      "Layer 148: conv5_block1_2_relu, Trainable: True\n",
      "Layer 149: conv5_block1_0_conv, Trainable: True\n",
      "Layer 150: conv5_block1_3_conv, Trainable: True\n",
      "Layer 151: conv5_block1_0_bn, Trainable: True\n",
      "Layer 152: conv5_block1_3_bn, Trainable: True\n",
      "Layer 153: conv5_block1_add, Trainable: True\n",
      "Layer 154: conv5_block1_out, Trainable: True\n",
      "Layer 155: conv5_block2_1_conv, Trainable: True\n",
      "Layer 156: conv5_block2_1_bn, Trainable: True\n",
      "Layer 157: conv5_block2_1_relu, Trainable: True\n",
      "Layer 158: conv5_block2_2_conv, Trainable: True\n",
      "Layer 159: conv5_block2_2_bn, Trainable: True\n",
      "Layer 160: conv5_block2_2_relu, Trainable: True\n",
      "Layer 161: conv5_block2_3_conv, Trainable: True\n",
      "Layer 162: conv5_block2_3_bn, Trainable: True\n",
      "Layer 163: conv5_block2_add, Trainable: True\n",
      "Layer 164: conv5_block2_out, Trainable: True\n",
      "Layer 165: conv5_block3_1_conv, Trainable: True\n",
      "Layer 166: conv5_block3_1_bn, Trainable: True\n",
      "Layer 167: conv5_block3_1_relu, Trainable: True\n",
      "Layer 168: conv5_block3_2_conv, Trainable: True\n",
      "Layer 169: conv5_block3_2_bn, Trainable: True\n",
      "Layer 170: conv5_block3_2_relu, Trainable: True\n",
      "Layer 171: conv5_block3_3_conv, Trainable: True\n",
      "Layer 172: conv5_block3_3_bn, Trainable: True\n",
      "Layer 173: conv5_block3_add, Trainable: True\n",
      "Layer 174: conv5_block3_out, Trainable: True\n",
      "Layer 175: avg_pool, Trainable: True\n",
      "Layer 176: predictions, Trainable: True\n"
     ]
    }
   ],
   "source": [
    "# load a pretrained ResNet50 Model\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# display the models architecture\n",
    "# model.summary()\n",
    "\n",
    "# access specific layers\n",
    "# for i, layers in enumerate(model.layers):\n",
    "#     print(f\"Layer {i}: {layers.name}, Trainable: {layers.trainable}\")\n",
    "\n",
    "for layer in model.layers[:-10]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb8afd",
   "metadata": {},
   "source": [
    "Pytorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6991f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d6215d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Model:/n ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n",
      "Layer: conv1.weight, Trainable: True\n",
      "Layer: bn1.weight, Trainable: True\n",
      "Layer: bn1.bias, Trainable: True\n",
      "Layer: layer1.0.conv1.weight, Trainable: True\n",
      "Layer: layer1.0.bn1.weight, Trainable: True\n",
      "Layer: layer1.0.bn1.bias, Trainable: True\n",
      "Layer: layer1.0.conv2.weight, Trainable: True\n",
      "Layer: layer1.0.bn2.weight, Trainable: True\n",
      "Layer: layer1.0.bn2.bias, Trainable: True\n",
      "Layer: layer1.0.conv3.weight, Trainable: True\n",
      "Layer: layer1.0.bn3.weight, Trainable: True\n",
      "Layer: layer1.0.bn3.bias, Trainable: True\n",
      "Layer: layer1.0.downsample.0.weight, Trainable: True\n",
      "Layer: layer1.0.downsample.1.weight, Trainable: True\n",
      "Layer: layer1.0.downsample.1.bias, Trainable: True\n",
      "Layer: layer1.1.conv1.weight, Trainable: True\n",
      "Layer: layer1.1.bn1.weight, Trainable: True\n",
      "Layer: layer1.1.bn1.bias, Trainable: True\n",
      "Layer: layer1.1.conv2.weight, Trainable: True\n",
      "Layer: layer1.1.bn2.weight, Trainable: True\n",
      "Layer: layer1.1.bn2.bias, Trainable: True\n",
      "Layer: layer1.1.conv3.weight, Trainable: True\n",
      "Layer: layer1.1.bn3.weight, Trainable: True\n",
      "Layer: layer1.1.bn3.bias, Trainable: True\n",
      "Layer: layer1.2.conv1.weight, Trainable: True\n",
      "Layer: layer1.2.bn1.weight, Trainable: True\n",
      "Layer: layer1.2.bn1.bias, Trainable: True\n",
      "Layer: layer1.2.conv2.weight, Trainable: True\n",
      "Layer: layer1.2.bn2.weight, Trainable: True\n",
      "Layer: layer1.2.bn2.bias, Trainable: True\n",
      "Layer: layer1.2.conv3.weight, Trainable: True\n",
      "Layer: layer1.2.bn3.weight, Trainable: True\n",
      "Layer: layer1.2.bn3.bias, Trainable: True\n",
      "Layer: layer2.0.conv1.weight, Trainable: True\n",
      "Layer: layer2.0.bn1.weight, Trainable: True\n",
      "Layer: layer2.0.bn1.bias, Trainable: True\n",
      "Layer: layer2.0.conv2.weight, Trainable: True\n",
      "Layer: layer2.0.bn2.weight, Trainable: True\n",
      "Layer: layer2.0.bn2.bias, Trainable: True\n",
      "Layer: layer2.0.conv3.weight, Trainable: True\n",
      "Layer: layer2.0.bn3.weight, Trainable: True\n",
      "Layer: layer2.0.bn3.bias, Trainable: True\n",
      "Layer: layer2.0.downsample.0.weight, Trainable: True\n",
      "Layer: layer2.0.downsample.1.weight, Trainable: True\n",
      "Layer: layer2.0.downsample.1.bias, Trainable: True\n",
      "Layer: layer2.1.conv1.weight, Trainable: True\n",
      "Layer: layer2.1.bn1.weight, Trainable: True\n",
      "Layer: layer2.1.bn1.bias, Trainable: True\n",
      "Layer: layer2.1.conv2.weight, Trainable: True\n",
      "Layer: layer2.1.bn2.weight, Trainable: True\n",
      "Layer: layer2.1.bn2.bias, Trainable: True\n",
      "Layer: layer2.1.conv3.weight, Trainable: True\n",
      "Layer: layer2.1.bn3.weight, Trainable: True\n",
      "Layer: layer2.1.bn3.bias, Trainable: True\n",
      "Layer: layer2.2.conv1.weight, Trainable: True\n",
      "Layer: layer2.2.bn1.weight, Trainable: True\n",
      "Layer: layer2.2.bn1.bias, Trainable: True\n",
      "Layer: layer2.2.conv2.weight, Trainable: True\n",
      "Layer: layer2.2.bn2.weight, Trainable: True\n",
      "Layer: layer2.2.bn2.bias, Trainable: True\n",
      "Layer: layer2.2.conv3.weight, Trainable: True\n",
      "Layer: layer2.2.bn3.weight, Trainable: True\n",
      "Layer: layer2.2.bn3.bias, Trainable: True\n",
      "Layer: layer2.3.conv1.weight, Trainable: True\n",
      "Layer: layer2.3.bn1.weight, Trainable: True\n",
      "Layer: layer2.3.bn1.bias, Trainable: True\n",
      "Layer: layer2.3.conv2.weight, Trainable: True\n",
      "Layer: layer2.3.bn2.weight, Trainable: True\n",
      "Layer: layer2.3.bn2.bias, Trainable: True\n",
      "Layer: layer2.3.conv3.weight, Trainable: True\n",
      "Layer: layer2.3.bn3.weight, Trainable: True\n",
      "Layer: layer2.3.bn3.bias, Trainable: True\n",
      "Layer: layer3.0.conv1.weight, Trainable: True\n",
      "Layer: layer3.0.bn1.weight, Trainable: True\n",
      "Layer: layer3.0.bn1.bias, Trainable: True\n",
      "Layer: layer3.0.conv2.weight, Trainable: True\n",
      "Layer: layer3.0.bn2.weight, Trainable: True\n",
      "Layer: layer3.0.bn2.bias, Trainable: True\n",
      "Layer: layer3.0.conv3.weight, Trainable: True\n",
      "Layer: layer3.0.bn3.weight, Trainable: True\n",
      "Layer: layer3.0.bn3.bias, Trainable: True\n",
      "Layer: layer3.0.downsample.0.weight, Trainable: True\n",
      "Layer: layer3.0.downsample.1.weight, Trainable: True\n",
      "Layer: layer3.0.downsample.1.bias, Trainable: True\n",
      "Layer: layer3.1.conv1.weight, Trainable: True\n",
      "Layer: layer3.1.bn1.weight, Trainable: True\n",
      "Layer: layer3.1.bn1.bias, Trainable: True\n",
      "Layer: layer3.1.conv2.weight, Trainable: True\n",
      "Layer: layer3.1.bn2.weight, Trainable: True\n",
      "Layer: layer3.1.bn2.bias, Trainable: True\n",
      "Layer: layer3.1.conv3.weight, Trainable: True\n",
      "Layer: layer3.1.bn3.weight, Trainable: True\n",
      "Layer: layer3.1.bn3.bias, Trainable: True\n",
      "Layer: layer3.2.conv1.weight, Trainable: True\n",
      "Layer: layer3.2.bn1.weight, Trainable: True\n",
      "Layer: layer3.2.bn1.bias, Trainable: True\n",
      "Layer: layer3.2.conv2.weight, Trainable: True\n",
      "Layer: layer3.2.bn2.weight, Trainable: True\n",
      "Layer: layer3.2.bn2.bias, Trainable: True\n",
      "Layer: layer3.2.conv3.weight, Trainable: True\n",
      "Layer: layer3.2.bn3.weight, Trainable: True\n",
      "Layer: layer3.2.bn3.bias, Trainable: True\n",
      "Layer: layer3.3.conv1.weight, Trainable: True\n",
      "Layer: layer3.3.bn1.weight, Trainable: True\n",
      "Layer: layer3.3.bn1.bias, Trainable: True\n",
      "Layer: layer3.3.conv2.weight, Trainable: True\n",
      "Layer: layer3.3.bn2.weight, Trainable: True\n",
      "Layer: layer3.3.bn2.bias, Trainable: True\n",
      "Layer: layer3.3.conv3.weight, Trainable: True\n",
      "Layer: layer3.3.bn3.weight, Trainable: True\n",
      "Layer: layer3.3.bn3.bias, Trainable: True\n",
      "Layer: layer3.4.conv1.weight, Trainable: True\n",
      "Layer: layer3.4.bn1.weight, Trainable: True\n",
      "Layer: layer3.4.bn1.bias, Trainable: True\n",
      "Layer: layer3.4.conv2.weight, Trainable: True\n",
      "Layer: layer3.4.bn2.weight, Trainable: True\n",
      "Layer: layer3.4.bn2.bias, Trainable: True\n",
      "Layer: layer3.4.conv3.weight, Trainable: True\n",
      "Layer: layer3.4.bn3.weight, Trainable: True\n",
      "Layer: layer3.4.bn3.bias, Trainable: True\n",
      "Layer: layer3.5.conv1.weight, Trainable: True\n",
      "Layer: layer3.5.bn1.weight, Trainable: True\n",
      "Layer: layer3.5.bn1.bias, Trainable: True\n",
      "Layer: layer3.5.conv2.weight, Trainable: True\n",
      "Layer: layer3.5.bn2.weight, Trainable: True\n",
      "Layer: layer3.5.bn2.bias, Trainable: True\n",
      "Layer: layer3.5.conv3.weight, Trainable: True\n",
      "Layer: layer3.5.bn3.weight, Trainable: True\n",
      "Layer: layer3.5.bn3.bias, Trainable: True\n",
      "Layer: layer4.0.conv1.weight, Trainable: True\n",
      "Layer: layer4.0.bn1.weight, Trainable: True\n",
      "Layer: layer4.0.bn1.bias, Trainable: True\n",
      "Layer: layer4.0.conv2.weight, Trainable: True\n",
      "Layer: layer4.0.bn2.weight, Trainable: True\n",
      "Layer: layer4.0.bn2.bias, Trainable: True\n",
      "Layer: layer4.0.conv3.weight, Trainable: True\n",
      "Layer: layer4.0.bn3.weight, Trainable: True\n",
      "Layer: layer4.0.bn3.bias, Trainable: True\n",
      "Layer: layer4.0.downsample.0.weight, Trainable: True\n",
      "Layer: layer4.0.downsample.1.weight, Trainable: True\n",
      "Layer: layer4.0.downsample.1.bias, Trainable: True\n",
      "Layer: layer4.1.conv1.weight, Trainable: True\n",
      "Layer: layer4.1.bn1.weight, Trainable: True\n",
      "Layer: layer4.1.bn1.bias, Trainable: True\n",
      "Layer: layer4.1.conv2.weight, Trainable: True\n",
      "Layer: layer4.1.bn2.weight, Trainable: True\n",
      "Layer: layer4.1.bn2.bias, Trainable: True\n",
      "Layer: layer4.1.conv3.weight, Trainable: True\n",
      "Layer: layer4.1.bn3.weight, Trainable: True\n",
      "Layer: layer4.1.bn3.bias, Trainable: True\n",
      "Layer: layer4.2.conv1.weight, Trainable: True\n",
      "Layer: layer4.2.bn1.weight, Trainable: True\n",
      "Layer: layer4.2.bn1.bias, Trainable: True\n",
      "Layer: layer4.2.conv2.weight, Trainable: True\n",
      "Layer: layer4.2.bn2.weight, Trainable: True\n",
      "Layer: layer4.2.bn2.bias, Trainable: True\n",
      "Layer: layer4.2.conv3.weight, Trainable: True\n",
      "Layer: layer4.2.bn3.weight, Trainable: True\n",
      "Layer: layer4.2.bn3.bias, Trainable: True\n",
      "Layer: fc.weight, Trainable: True\n",
      "Layer: fc.bias, Trainable: True\n"
     ]
    }
   ],
   "source": [
    "# load a pre trained ResNet50 Model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# print model architecture\n",
    "# print(model)\n",
    "\n",
    "# freeze the model parameters\n",
    "for param in model.parameters():\n",
    "   param.requires_grad = False\n",
    "\n",
    "# modify the final layer for a new task\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_features, 10)\n",
    "\n",
    "# print(\"Modified Model:/n\", model)\n",
    "\n",
    "# for name, parm in model.named_parameters():\n",
    "#     print(f\"Layer: {name}, Trainable: {parm.requires_grad}\")\n",
    "\n",
    "# how to unfreeze layers\n",
    "for name, param in model.named_parameters():\n",
    "   if \"layer4\" in name:\n",
    "      param.requires_grad = True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
