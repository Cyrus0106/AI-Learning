{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06e8957",
   "metadata": {},
   "source": [
    "### Building Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed8638",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch and Its Core Components\n",
    "\n",
    "### What is PyTorch?\n",
    "PyTorch is an open-source deep learning framework developed by Facebook's AI Research lab. It provides flexibility and dynamic computation graphs, making it easy to build, train, and deploy machine learning models. PyTorch is widely used for research and production due to its intuitive interface and strong GPU acceleration.\n",
    "\n",
    "### Core Components of PyTorch\n",
    "\n",
    "- **Tensors**:  \n",
    "    Multi-dimensional arrays similar to NumPy arrays, but with additional capabilities such as GPU acceleration for faster computation. Tensors are the fundamental building blocks for all computations in PyTorch.\n",
    "\n",
    "- **Autograd**:  \n",
    "    PyTorch's automatic differentiation engine that computes gradients for all tensor operations. This is essential for training neural networks using backpropagation.\n",
    "\n",
    "- **torch.nn Module**:  \n",
    "    Provides a suite of tools to define and train neural networks, including layers (e.g., `Linear`, `Conv2d`), activation functions (e.g., `ReLU`, `Sigmoid`), and loss functions (e.g., `CrossEntropyLoss`, `MSELoss`).\n",
    "\n",
    "- **Optimizers**:  \n",
    "    PyTorch offers various optimization algorithms (e.g., SGD, Adam) in the `torch.optim` module to update model parameters based on computed gradients.\n",
    "\n",
    "---\n",
    "\n",
    "## Building a Neural Network in PyTorch\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Define the Model**  \n",
    "     Use the `torch.nn.Module` class to create a neural network by specifying layers and the forward propagation logic.\n",
    "\n",
    "2. **Define the Loss Function**  \n",
    "     Choose a suitable loss function (e.g., cross-entropy loss for classification, mean squared error for regression) to measure the difference between predictions and true values.\n",
    "\n",
    "3. **Define the Optimizer**  \n",
    "     Select an optimizer (e.g., Adam, SGD) from `torch.optim` to update the model's weights during training.\n",
    "\n",
    "---\n",
    "\n",
    "## Training, Evaluating, and Saving a Model in PyTorch\n",
    "\n",
    "- **Training**:  \n",
    "    - Perform a forward pass to compute predictions.\n",
    "    - Calculate the loss using the chosen loss function.\n",
    "    - Perform a backward pass to compute gradients using autograd.\n",
    "    - Update model weights using the optimizer.\n",
    "    - Repeat for multiple epochs over the dataset.\n",
    "\n",
    "- **Evaluation**:  \n",
    "    - Test the trained model on unseen data (validation or test set).\n",
    "    - Calculate evaluation metrics such as accuracy, precision, recall, or F1-score to assess model performance.\n",
    "\n",
    "- **Saving and Loading Models**:  \n",
    "    - Save the model's parameters using `torch.save(model.state_dict(), PATH)`.\n",
    "    - Load the saved parameters into a model using `model.load_state_dict(torch.load(PATH))`.\n",
    "    - This allows you to reuse trained models without retraining.\n",
    "\n",
    "---\n",
    "\n",
    "PyTorch's flexibility, ease of use, and strong community support make it a popular choice for both beginners and advanced practitioners in deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b109a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a11c2",
   "metadata": {},
   "source": [
    "Define transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd3ef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 60000\n",
      "Test Data Size: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# load datasets\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transform, download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training Data Size: {len(train_dataset)}\")\n",
    "print(f\"Test Data Size: {len(test_dataset)}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b8ed3",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1, Loss: 0.35669283079504965\n",
      "Epoch 2, Loss: 0.1668147985600556\n",
      "Epoch 3, Loss: 0.12700036020614205\n",
      "Epoch 4, Loss: 0.10266157542467118\n",
      "Epoch 5, Loss: 0.08850854687945296\n",
      "Accuracy: 0.9657\n",
      "Accuracy: 0.9657\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "print(model)\n",
    "\n",
    "# define loss function and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            # zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward pass and optimise\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=5)\n",
    "\n",
    "\n",
    "# evaluate loop\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {correct/total}\")\n",
    "\n",
    "\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# save the model\n",
    "torch.save(model.state_dict(), \"mnist_model.pth\")\n",
    "\n",
    "# reload the model\n",
    "loaded_model = NeuralNetwork()\n",
    "loaded_model.load_state_dict(torch.load(\"mnist_model.pth\"))\n",
    "\n",
    "# verify loaded model performance\n",
    "evaluate_model(loaded_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e95da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
