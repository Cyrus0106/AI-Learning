{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5689f182",
   "metadata": {},
   "source": [
    "### Introduction to Sequence Modeling and RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73ac9e",
   "metadata": {},
   "source": [
    "## What is Sequence Modeling?\n",
    "\n",
    "Sequence modeling involves predicting or generating outputs based on sequential data. It is designed to capture temporal or contextual dependencies within data, making it essential for tasks where the order of data points matters.\n",
    "\n",
    "### Why is Sequence Modeling Important?\n",
    "\n",
    "- **Natural Language Processing (NLP):** Tasks such as language modeling, machine translation, and sentiment analysis depend on understanding sequential relationships in text.\n",
    "- **Time-Series Analysis:** Sequence models are essential for tasks like stock price prediction, weather forecasting, and sensor data analysis, where data points are ordered in time.\n",
    "- **Speech and Audio Processing:** Recognizing spoken words or music requires understanding the sequence of sounds.\n",
    "- **Video Analysis:** Understanding actions in videos involves modeling sequences of frames.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are specialized neural networks designed for sequence modeling. Unlike traditional neural networks, RNNs include recurrent connections that allow them to maintain a \"memory\" of previous inputs, enabling them to process sequences of data.\n",
    "\n",
    "### Structure of an RNN\n",
    "\n",
    "- **Input Layer:** Processes sequential data one step at a time.\n",
    "- **Hidden State:** Maintains information about past inputs, acting as the network's memory.\n",
    "- **Recurrent Connections:** Pass hidden states from one time step to the next, allowing information to persist.\n",
    "\n",
    "### Key Concepts in RNNs\n",
    "\n",
    "- **Hidden States:** Represent the memory of the network at each time step, capturing information from previous inputs.\n",
    "- **Recurrent Connections:** Enable information sharing across time steps, making RNNs effective for sequential data.\n",
    "- **Vanishing Gradient Problem:** A challenge in training RNNs on long sequences, where gradients can become very small, making learning difficult. Solutions include architectures like LSTM and GRU.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Applications of RNNs in Machine Learning\n",
    "\n",
    "- **Text Generation:** Generating new text based on learned patterns.\n",
    "- **Language Translation:** Translating text from one language to another.\n",
    "- **Stock Price Prediction:** Forecasting future stock prices based on historical data.\n",
    "- **Speech Recognition:** Converting spoken language into text.\n",
    "- **Video Frame Prediction:** Predicting future frames in a video sequence.\n",
    "- **Music Generation:** Creating new music sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d25abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "vocab_size = 10000\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7a036",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512b606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (25000, 200)\n",
      "Testing Data Shape: (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\")\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Testing Data Shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139d9ea",
   "metadata": {},
   "source": [
    "build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c988045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.5138 - loss: 0.6949 - val_accuracy: 0.5176 - val_loss: 0.6931\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.5288 - loss: 0.6905 - val_accuracy: 0.5254 - val_loss: 0.6885\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.5731 - loss: 0.6638 - val_accuracy: 0.5471 - val_loss: 0.6814\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.5973 - loss: 0.6353 - val_accuracy: 0.5652 - val_loss: 0.6795\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.6267 - loss: 0.5976 - val_accuracy: 0.5842 - val_loss: 0.6658\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.6519 - loss: 0.5550 - val_accuracy: 0.5704 - val_loss: 0.7125\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.6469 - loss: 0.5672 - val_accuracy: 0.5916 - val_loss: 0.6681\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6778 - loss: 0.5183 - val_accuracy: 0.5910 - val_loss: 0.6803\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.6741 - loss: 0.5061 - val_accuracy: 0.5885 - val_loss: 0.7015\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.6829 - loss: 0.4871 - val_accuracy: 0.5968 - val_loss: 0.7166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,939,077</span> (15.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,939,077\u001b[0m (15.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,025</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,313,025\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,626,052</span> (10.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,626,052\u001b[0m (10.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim = vocab_size, output_dim=128),\n",
    "    SimpleRNN(128, activation=\"tanh\", return_sequences=False),\n",
    "    Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c17b8",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4493c75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.6998 - loss: 0.4662 - val_accuracy: 0.6870 - val_loss: 0.4709\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.6905 - loss: 0.4627 - val_accuracy: 0.6868 - val_loss: 0.4962\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.7042 - loss: 0.4489 - val_accuracy: 0.6686 - val_loss: 0.5442\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.6987 - loss: 0.4493 - val_accuracy: 0.6706 - val_loss: 0.5329\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.6973 - loss: 0.4454 - val_accuracy: 0.6688 - val_loss: 0.5375\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5916 - loss: 0.7662\n",
      "Test Loss: 0.7717415690422058, Test Accuracy: 0.5879999995231628\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3c8e0",
   "metadata": {},
   "source": [
    "create and train model with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081fd5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6939052312880221\n",
      "Epoch 2, Loss: 0.6783899852381948\n",
      "Epoch 3, Loss: 0.6835587679425164\n",
      "Epoch 4, Loss: 0.6877340893153949\n",
      "Epoch 5, Loss: 0.6762721046157505\n",
      "Test Loss: 0.6793279647827148, Test Accuracy: 0.5436800122261047\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return torch.sigmoid(self.fc(hidden.squeeze()))\n",
    "    \n",
    "model = RNNModel(vocab_size=10000, embedding_dim=128, hidden_dim=128, output_dim=1)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_rnn(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0 \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch).squeeze(1)\n",
    "            loss = criterion(predictions, y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "train_rnn(model, train_loader ,criterion, optimizer)\n",
    "\n",
    "def evaluate_rnn(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(torch.tensor(X_test)).squeeze(1)\n",
    "        loss = criterion(predictions, torch.tensor(y_test).float())\n",
    "        accuracy = ((predictions>0.5 ) == torch.tensor(y_test).float()).float().mean().item()\n",
    "    print(f\"Test Loss: {loss.item()}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "evaluate_rnn(model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
