{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89be622d",
   "metadata": {},
   "source": [
    "### Understanding RNN architecture and Backpropagation Through Time (BPTT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0fa73",
   "metadata": {},
   "source": [
    "#### Detailed Architecture of RNN\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a class of neural networks designed to process sequential data by maintaining a form of memory of previous inputs. They are particularly well-suited for tasks where context or order matters, such as language modeling, time series prediction, and speech recognition.\n",
    "\n",
    "---\n",
    "\n",
    "### **Components of an RNN**\n",
    "\n",
    "- **Input Layer:**  \n",
    "    Receives sequential data, where each element of the sequence is fed into the network at each time step \\( t \\).  \n",
    "    *Example:* For a sentence, each word (or character) is an input at a different time step.\n",
    "\n",
    "- **Hidden Layer:**  \n",
    "    Maintains a \"memory\" of past inputs through recurrent connections. The hidden state at time \\( t \\) (\\( h_t \\)) is updated based on the current input and the previous hidden state.  \n",
    "    The update rule is:  \n",
    "    \\[\n",
    "    h_t = f(W_h h_{t-1} + W_x x_t + b_h)\n",
    "    \\]\n",
    "    where:\n",
    "    - \\( h_{t-1} \\): Hidden state from the previous time step\n",
    "    - \\( x_t \\): Input at the current time step\n",
    "    - \\( W_h \\): Weight matrix for recurrent (hidden-to-hidden) connections\n",
    "    - \\( W_x \\): Weight matrix for input-to-hidden connections\n",
    "    - \\( b_h \\): Bias term\n",
    "    - \\( f \\): Non-linear activation function (commonly tanh or ReLU)\n",
    "\n",
    "    The hidden state acts as a summary of all previous inputs, allowing the network to retain information over time.\n",
    "\n",
    "- **Output Layer:**  \n",
    "    Produces the output at each time step, which can be used for tasks like sequence prediction, classification, or generation.  \n",
    "    The output at time \\( t \\) is typically computed as:  \n",
    "    \\[\n",
    "    y_t = g(W_y h_t + b_y)\n",
    "    \\]\n",
    "    where:\n",
    "    - \\( W_y \\): Weight matrix for hidden-to-output connections\n",
    "    - \\( b_y \\): Output bias\n",
    "    - \\( g \\): Activation function (e.g., softmax for classification, linear for regression)\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "\n",
    "- **Parameter Sharing:**  \n",
    "    RNNs share parameters (weights and biases) across all time steps, making them efficient for sequential data and reducing the number of parameters to learn.\n",
    "- **Temporal Dependencies:**  \n",
    "    The recurrent connection allows information to persist, enabling the network to learn temporal dependencies and context from previous inputs.\n",
    "- **Flexible Output:**  \n",
    "    RNNs can be configured for different sequence tasks:  \n",
    "    - One-to-one (e.g., image classification)  \n",
    "    - One-to-many (e.g., image captioning)  \n",
    "    - Many-to-one (e.g., sentiment analysis)  \n",
    "    - Many-to-many (e.g., machine translation)\n",
    "\n",
    "---\n",
    "\n",
    "### **Backpropagation Through Time (BPTT)**\n",
    "\n",
    "**What is BPTT?**  \n",
    "BPTT is an extension of standard backpropagation to handle sequential data in RNNs. It calculates gradients for each time step and propagates them backward through the sequence, updating the shared weights.\n",
    "\n",
    "**Steps of BPTT:**\n",
    "1. **Unroll the RNN:**  \n",
    "     The RNN is \"unrolled\" across the sequence for a fixed number of time steps, creating a computational graph where each time step is a layer.\n",
    "2. **Compute the Loss:**  \n",
    "     The loss is computed at each time step (or only at the final step, depending on the task).\n",
    "3. **Backpropagate Errors:**  \n",
    "     Errors are backpropagated through all time steps to update the shared weights, taking into account dependencies across time.\n",
    "\n",
    "---\n",
    "\n",
    "### **Challenges in BPTT**\n",
    "\n",
    "- **Vanishing Gradient Problem:**  \n",
    "    As gradients are propagated backward through many time steps, they can shrink exponentially, making them extremely small. This leads to very slow or stalled learning for long-term dependencies, as the network fails to update weights effectively for earlier time steps.\n",
    "    - This problem is especially severe with long sequences and deep unrollings.\n",
    "    - It limits the ability of standard RNNs to capture relationships between distant elements in a sequence.\n",
    "    - **Mitigation:**  \n",
    "        - Use specialized architectures like Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), which introduce gating mechanisms to help preserve gradients and maintain long-term dependencies.\n",
    "        - Proper weight initialization and using activation functions less prone to saturation (like ReLU) can also help.\n",
    "\n",
    "- **Exploding Gradient Problem:**  \n",
    "    Gradients can grow exponentially, causing numerical instability during training.\n",
    "    - **Mitigation:**  \n",
    "        - Use gradient clipping to cap the gradients during backpropagation.\n",
    "        - Careful tuning of learning rates.\n",
    "\n",
    "---\n",
    "\n",
    "### **Limitations of Vanilla RNNs**\n",
    "\n",
    "- **Short-Term Memory:**  \n",
    "    Struggle to learn dependencies in long sequences due to vanishing gradients, making it hard to capture long-term context.\n",
    "- **Sequential Computation:**  \n",
    "    Cannot parallelize training across time steps, making them computationally expensive and slow for long sequences.\n",
    "- **Sensitive Initialization:**  \n",
    "    Performance depends heavily on proper weight initialization and learning rates. Poor choices can exacerbate vanishing/exploding gradients.\n",
    "- **Difficulty with Long Sequences:**  \n",
    "    Standard RNNs are not well-suited for tasks requiring the retention of information over many time steps.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications of RNNs**\n",
    "\n",
    "- Natural Language Processing (NLP): Language modeling, machine translation, text generation\n",
    "- Time Series Prediction: Stock prices, weather forecasting\n",
    "- Speech Recognition: Transcribing audio to text\n",
    "- Sequence Generation: Music, handwriting\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "RNNs are powerful for modeling sequential data but face significant challenges with long-term dependencies due to vanishing and exploding gradients. Advanced architectures like LSTM and GRU are commonly used to address these issues and enable learning from longer sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93c2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc5466",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f29cfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape (25000, 200)\n",
      "Testing Data Shape (25000, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.5062 - loss: 0.6950 - val_accuracy: 0.5380 - val_loss: 0.6855\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.5895 - loss: 0.6453 - val_accuracy: 0.5434 - val_loss: 0.6891\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.6326 - loss: 0.5996 - val_accuracy: 0.5434 - val_loss: 0.6772\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.6105 - loss: 0.6093 - val_accuracy: 0.5428 - val_loss: 0.6820\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.6157 - loss: 0.6015 - val_accuracy: 0.5420 - val_loss: 0.6977\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5386 - loss: 0.7019\n",
      "Loss: 0.7031590342521667\n",
      "Accuracy: 0.5343999862670898\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "max_len = 200\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\")\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "print(f\"Training Data Shape {X_train.shape}\")\n",
    "print(f\"Testing Data Shape {X_test.shape}\")\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim = vocab_size, output_dim = 128),\n",
    "    SimpleRNN(128, activation=\"tanh\", return_sequences=False),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cccd66",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ec6fe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss:0.6838183702562776\n",
      "Epoch 2, Loss:0.6490452869240281\n",
      "Epoch 3, Loss:0.6204159514754629\n",
      "Epoch 4, Loss:0.5934461690199649\n",
      "Epoch 5, Loss:0.5570540175870862\n",
      "Test Loss: 0.6885334253311157, Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return torch.sigmoid(self.fc(hidden.squeeze(0)))\n",
    "    \n",
    "model = RNNModel(vocab_size=10000, embedding_dim=128, hidden_dim=128, output_dim=1)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_rnn(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch).squeeze(1)\n",
    "            loss = criterion(predictions, y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss:{epoch_loss/len(train_loader)}\")\n",
    "\n",
    "train_rnn(model,train_loader,criterion,optimizer)\n",
    "\n",
    "def evalutate_rnn(model,X_test,y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(torch.tensor(X_test)).squeeze(1)\n",
    "        loss = criterion(predictions, torch.tensor(y_test).float())\n",
    "        accuracy = ((predictions>0) == torch.tensor(y_test).float()).float().mean().item()\n",
    "    print(F\"Test Loss: {loss.item()}, Test accuracy: {accuracy}\")\n",
    "\n",
    "evalutate_rnn(model,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
